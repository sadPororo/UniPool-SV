# [MODEL HYPERPARAMS] ______________________________________________________________
# Wav2Vec 2.0
backbone_cfg: 'facebook/wav2vec2-base'  # 'facebook/wav2vec2-base' | 'facebook/wav2vec2-large' | 'facebook/wav2vec2-large-lv60' | 'microsoft/wavlm-base' | 'microsoft/wavlm-large'
use_pretrain: False
frz_pretrain: False

# D3 Net
n_layers: 0
n_blocks: 1
conv_dim: 128

# Attn Pool
pool_dim: 192

# Loss
num_loss_heads: 1

# [AUGMENTATIONS] __________________________________________________________________
# Span-out
spanout: False
spanout_prob: 0.3
span_mask_prob: 0.05
span_mask_length: 3  # This will drop about 15% of sequence

# Spec-augment
specaug: False
specaug_prob: 0.3
time_mask_prob: 0.05
time_mask_length: 10 # This will mask about 45% of sequence
feat_mask_prob: 0.0
feat_mask_length: 10

# OneCycleLR()
max_lr: 0.003
pct_start: 0.1

bsz_ratio: 2 # if './config/common/training-base-config.yaml--eval_batch_size' is not configured, batch size at evaluation phase will be (train_batch_size / bsz_ratio)
              # else '--eval_batch_size' is configured, batch size will be overriden at the evaluation phase.
